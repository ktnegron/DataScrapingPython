{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,urllib,json,requests, bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data through specific API Package: Edgar\n",
    "https://www.sec.gov/edgar/searchedgar/companysearch.html\n",
    "\n",
    "https://sec-edgar-downloader.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U sec-edgar-downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sec_edgar_downloader import Downloader\n",
    "\n",
    "# Initialize a downloader instance. If no argument is passed\n",
    "# to the constructor, the package will download filings to\n",
    "# the current working directory.\n",
    "dl = Downloader(\"./\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all 8-K filings for Apple (ticker: AAPL)\n",
    "dl.get(\"8-K\", \"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get all 8-K filings for Apple, including filing amends (8-K/A)\n",
    "# dl.get(\"8-K\", \"AAPL\", include_amends=True)\n",
    "\n",
    "# # Get all 8-K filings for Apple after January 1, 2017 and before March 25, 2017\n",
    "# # Note: after and before strings must be in the form \"YYYY-MM-DD\"\n",
    "# dl.get(\"8-K\", \"AAPL\", after=\"2017-01-01\", before=\"2017-03-25\")\n",
    "\n",
    "# # Get the five most recent 8-K filings for Apple\n",
    "# dl.get(\"8-K\", \"AAPL\", amount=5)\n",
    "\n",
    "# # Get all 10-K filings for Microsoft\n",
    "# dl.get(\"10-K\", \"MSFT\")\n",
    "\n",
    "# # Get the latest 10-K filing for Microsoft\n",
    "# dl.get(\"10-K\", \"MSFT\", amount=1)\n",
    "\n",
    "# # Get all 10-Q filings for Visa\n",
    "# dl.get(\"10-Q\", \"V\")\n",
    "\n",
    "# # Get all 13F-NT filings for the Vanguard Group\n",
    "# dl.get(\"13F-NT\", \"0000102909\")\n",
    "\n",
    "# # Get all 13F-HR filings for the Vanguard Group\n",
    "# dl.get(\"13F-HR\", \"0000102909\")\n",
    "\n",
    "# # Get all SC 13G filings for Apple\n",
    "# dl.get(\"SC 13G\", \"AAPL\")\n",
    "\n",
    "# # Get all SD filings for Apple\n",
    "# dl.get(\"SD\", \"AAPL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data through specific API Package: WRDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrds\n",
    "db = wrds.Connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.raw_sql(\"\"\"select GVKEY , CONM from comp.funda where fyear=2002\"\"\",date_cols=['date']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Alternative to Web Scraping: APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a website provides an API, then it is the best way to access data. You can specify query parameters to get the data that you precisely need, and you will get it in standard data transport format like JSON or XML, so there is no ambiguity. Unfortunately, not all the websites provide a public API for data access. Even when they do, they have some rate limit on how many requests you can send in a second, minute or a day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.twitter.com/2/tweets/search/recent?query=(from:elonmusk)&tweet.fields=created_at'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = 'https://api.twitter.com/2/'\n",
    "end_point = 'tweets/search/recent'\n",
    "author = 'elonmusk'\n",
    "url = f'{base_url}{end_point}?query=(from:{author})&tweet.fields=created_at'\n",
    "\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "baerer_token = 'AAAAAAAAAAAAAAAAAAAAANs9XwEAAAAAYLf%2BurOHBec04v0HgPxPkM2Zsqc%3DsK49bTagxMYSXWTWZllMoF1b217pkI0EnLc2aDUhQC6k2INbR3'\n",
    "\n",
    "def bearer_oauth(r):\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {baerer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2TweetLookupPython\"\n",
    "    return r\n",
    "\n",
    "base_url = 'https://api.twitter.com/2/'\n",
    "end_point = 'tweets/search/recent'\n",
    "author = 'elonmusk'\n",
    "url = f'{base_url}{end_point}?query=(from:{author})&tweet.fields=created_at'\n",
    "\n",
    "response = requests.request(\"GET\", url, auth=bearer_oauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-06T04:34:26.000Z</td>\n",
       "      <td>1511562956588343298</td>\n",
       "      <td>RT @SpaceX: Falcon 9 and Dragon vertical at 39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-05T21:25:28.000Z</td>\n",
       "      <td>1511455000391729155</td>\n",
       "      <td>@pmarca @skepticaliblog Yikes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-05T18:59:56.000Z</td>\n",
       "      <td>1511418378057142275</td>\n",
       "      <td>@pmarca WaPo always good for a laugh 🤣🤣</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-05T18:53:45.000Z</td>\n",
       "      <td>1511416821789995011</td>\n",
       "      <td>@jack Thanks Jack!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-05T12:39:34.000Z</td>\n",
       "      <td>1511322655609303043</td>\n",
       "      <td>@paraga Looking forward to working with Parag ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-04-05T06:32:39.000Z</td>\n",
       "      <td>1511230314902953984</td>\n",
       "      <td>@PPathole @Erdayastronaut Yeah, single most an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-04-05T05:38:54.000Z</td>\n",
       "      <td>1511216790218895361</td>\n",
       "      <td>@Erdayastronaut That sounds reasonable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-04-05T04:56:59.000Z</td>\n",
       "      <td>1511206240667455489</td>\n",
       "      <td>@boztank @Liz_Wheeler Facebook gives me the wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-04-05T04:07:30.000Z</td>\n",
       "      <td>1511193789737672707</td>\n",
       "      <td>@OstynHyss @stevenmarkryan That is harder than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-04-05T04:02:51.000Z</td>\n",
       "      <td>1511192616662093830</td>\n",
       "      <td>@stevenmarkryan I mean, if the people vote ove...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at                   id  \\\n",
       "0  2022-04-06T04:34:26.000Z  1511562956588343298   \n",
       "1  2022-04-05T21:25:28.000Z  1511455000391729155   \n",
       "2  2022-04-05T18:59:56.000Z  1511418378057142275   \n",
       "3  2022-04-05T18:53:45.000Z  1511416821789995011   \n",
       "4  2022-04-05T12:39:34.000Z  1511322655609303043   \n",
       "5  2022-04-05T06:32:39.000Z  1511230314902953984   \n",
       "6  2022-04-05T05:38:54.000Z  1511216790218895361   \n",
       "7  2022-04-05T04:56:59.000Z  1511206240667455489   \n",
       "8  2022-04-05T04:07:30.000Z  1511193789737672707   \n",
       "9  2022-04-05T04:02:51.000Z  1511192616662093830   \n",
       "\n",
       "                                                text  \n",
       "0  RT @SpaceX: Falcon 9 and Dragon vertical at 39...  \n",
       "1                      @pmarca @skepticaliblog Yikes  \n",
       "2            @pmarca WaPo always good for a laugh 🤣🤣  \n",
       "3                                 @jack Thanks Jack!  \n",
       "4  @paraga Looking forward to working with Parag ...  \n",
       "5  @PPathole @Erdayastronaut Yeah, single most an...  \n",
       "6             @Erdayastronaut That sounds reasonable  \n",
       "7  @boztank @Liz_Wheeler Facebook gives me the wi...  \n",
       "8  @OstynHyss @stevenmarkryan That is harder than...  \n",
       "9  @stevenmarkryan I mean, if the people vote ove...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(response.json()['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": [\n",
      "        {\n",
      "            \"created_at\": \"2022-04-05T21:25:28.000Z\",\n",
      "            \"id\": \"1511455000391729155\",\n",
      "            \"text\": \"@pmarca @skepticaliblog Yikes\"\n",
      "        },\n",
      "        {\n",
      "            \"created_at\": \"2022-04-05T18:59:56.000Z\",\n",
      "            \"id\": \"1511418378057142275\",\n",
      "            \"text\": \"@pmarca WaPo always good for a laugh \\ud83e\\udd23\\ud83e\\udd23\"\n",
      "        },\n",
      "        {\n",
      "            \"created_at\": \"2022-04-05T18:53:45.000Z\",\n",
      "            \"id\": \"1511416821789995011\",\n",
      "            \"text\": \"@jack Thanks Jack!\"\n",
      "        },\n",
      "        {\n",
      "            \"created_at\": \"2022-04-05T12:39:34.000Z\",\n",
      "            \"id\": \"1511322655609303043\",\n",
      "            \"text\": \"@paraga Looking forward to working with Parag &amp; Twitter board to make significant improvements to Twitter in coming months!\"\n",
      "        },\n",
      "        {\n",
      "            \"created_at\": \"2022-04-05T06:32:39.000Z\",\n",
      "            \"id\": \"1511230314902953984\",\n",
      "            \"text\": \"@PPathole @Erdayastronaut Yeah, single most annoying problem on twitter imo\"\n",
      "        },\n",
      "        {\n",
      "            \"created_at\": \"2022-04-05T05:38:54.000Z\",\n",
      "            \"id\": \"1511216790218895361\",\n",
      "            \"text\": \"@Erdayastronaut That sounds reasonable\"\n",
      "        },\n",
      "        {\n",
      "            \"created_at\": \"2022-04-05T04:56:59.000Z\",\n",
      "            \"id\": \"1511206240667455489\",\n",
      "            \"text\": \"@boztank @Liz_Wheeler Facebook gives me the willies\"\n",
      "        },\n",
      "        {\n",
      "            \"created_at\": \"2022-04-05T04:07:30.000Z\",\n",
      "            \"id\": \"1511193789737672707\",\n",
      "            \"text\": \"@OstynHyss @stevenmarkryan That is harder than a boss battle in DS3!\"\n",
      "        },\n",
      "        {\n",
      "            \"created_at\": \"2022-04-05T04:02:51.000Z\",\n",
      "            \"id\": \"1511192616662093830\",\n",
      "            \"text\": \"@stevenmarkryan I mean, if the people vote overwhelmingly for something, it is at least *a* data point!\"\n",
      "        },\n",
      "        {\n",
      "            \"created_at\": \"2022-04-05T00:48:06.000Z\",\n",
      "            \"id\": \"1511143607385874434\",\n",
      "            \"text\": \"Do you want an edit button?\"\n",
      "        }\n",
      "    ],\n",
      "    \"meta\": {\n",
      "        \"newest_id\": \"1511455000391729155\",\n",
      "        \"next_token\": \"b26v89c19zqg8o3fpytlfq1nhso4jcddmkmt8ywesjud9\",\n",
      "        \"oldest_id\": \"1511143607385874434\",\n",
      "        \"result_count\": 10\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "baerer_token = 'AAAAAAAAAAAAAAAAAAAAANs9XwEAAAAAYLf%2BurOHBec04v0HgPxPkM2Zsqc%3DsK49bTagxMYSXWTWZllMoF1b217pkI0EnLc2aDUhQC6k2INbR3'\n",
    "\n",
    "def bearer_oauth(r):\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {baerer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2TweetLookupPython\"\n",
    "    return r\n",
    "\n",
    "base_url = 'https://api.twitter.com/2/'\n",
    "end_point = 'tweets/search/recent'\n",
    "author = 'elonmusk'\n",
    "url = f'{base_url}{end_point}?query=(from:{author})&tweet.fields=created_at'\n",
    "\n",
    "response = requests.request(\"GET\", url, auth=bearer_oauth)\n",
    "print(json.dumps(response.json(), indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you write any Python code, you need to get to know the website that you want to scrape. That should be your first step for any web scraping project you want to tackle. You’ll need to understand the site structure to extract the information that’s relevant for you. Start by opening the site you want to scrape with your favorite browser.\n",
    "\n",
    "Steps involved in inspecting data source are:\n",
    "1. Decipher the basic information in URL like base path and resource path\n",
    "2. Decipher various query parameters passed with url, and how they affect the returned result\n",
    "3. Look at structure of the HTML of the page by inspecting DOM Tree in Web Developers toolbar\n",
    "4. Figuring out how to locate various elements of interest using IDs, Classes, XPaths and DOM Parsings\n",
    "\n",
    "Once the structure of the page is clear, one can use any http requests package to download the HTML of the page as a text object. Python's requests package is one such package to get response of http request as text. We need to parse this text using some HTML parsing tool to extract various elements of interest. Beautiful Soup is a good package in python to solve this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mJOY\u001b[0m If you carry joy in your heart, you can heal any moment.\n",
      "\u001b[1mJOY\u001b[0m Joy blooms where minds and hearts are open.\n",
      "\u001b[1mWISDOM\u001b[0m Like water in the desert is wisdom to the soul.\n",
      "\u001b[1mWISDOM\u001b[0m You know the difference between knowledge and wisdom? Knowledge is knowing tomato is a fruit. Wisdom is knowing you don't put tomato in a fruit salad.\n",
      "\u001b[1mWISDOM\u001b[0m Yesterday I was clever, so I wanted to change the world. Today I am wise, so I am changing myself.\n",
      "\u001b[1mWISDOM\u001b[0m Turn your wounds into wisdom.\n",
      "\u001b[1mWISDOM\u001b[0m We don't receive wisdom; we must discover it for ourselves after a journey that no one can take for us or spare us.\n",
      "\u001b[1mKINDNESS\u001b[0m One kind word can warm three winter months.\n",
      "\u001b[1mKINDNESS\u001b[0m Good words bring good feelings to the heart. Speak with kindness, always. \n",
      "\u001b[1mKINDNESS\u001b[0m That’s what kindness is. It’s not doing something for someone else because they can’t, but because you can.\n",
      "\u001b[1mKINDNESS\u001b[0m Carry out a random act of kindness, with no expectation of reward, safe in the knowledge that one day someone might do the same for you.\n",
      "\u001b[1mKINDNESS\u001b[0m What wisdom can you find that is greater than kindness?\n",
      "\u001b[1mRESILIENCY\u001b[0m Do not judge me by my success, judge me by how many times I fell down and got back up again.\n",
      "\u001b[1mRESILIENCY\u001b[0m Life doesn’t get easier or more forgiving, we get stronger and more resilient.\n",
      "\u001b[1mRESILIENCY\u001b[0m When I dare to be powerful to use my strength in the service of my vision then it becomes less and less important whether I am afraid.\n",
      "\u001b[1mRESILIENCY\u001b[0m Like tiny seeds with potent power to push through tough ground and become mighty trees, we hold innate reserves of unimaginable strength. We are resilient.\n",
      "\u001b[1mPEACE\u001b[0m When the power of love overcomes the love of power the world will know peace.\n",
      "\u001b[1mPEACE\u001b[0m Peace is a day-to-day problem, the product of a multitude of events and judgments. Peace is not an ‘is,’ it is a ‘becoming.’\n",
      "\u001b[1mPEACE\u001b[0m Inner peace doesn’t come from getting what we want, but from remembering who we are.\n",
      "\u001b[1mPEACE\u001b[0m Peace is its own reward.\n",
      "\u001b[1mPEACE\u001b[0m It isn’t enough to talk about peace. One must believe in it. And it isn’t enough to believe in it. One must work at it.\n",
      "\u001b[1mOPTIMISM\u001b[0m Optimism is a strategy for making a better future. Because unless you believe that the future can be better, you are unlikely to step up and take responsibility for making it so.\n",
      "\u001b[1mOPTIMISM\u001b[0m And you ask “what if I fall?\" Oh but my darling, what if you fly?”\n",
      "\u001b[1mOPTIMISM\u001b[0m It’s not that optimism solves all of life’s problems; it is just that it can sometimes make the difference between coping and collapsing. \n",
      "\u001b[1mOPTIMISM\u001b[0m Perpetual optimism is a force multiplier.\n",
      "\u001b[1mOPTIMISM\u001b[0m No pessimist ever discovered the secrets of the stars, or sailed to an uncharted land, or opened a new heaven to the horizon of the spirit.\n",
      "\u001b[1mCONFIDENCE\u001b[0m Stay afraid, but do it anyway. What’s important is the action. You don’t have to wait to be confident. Just do it and eventually the confidence will follow. \n",
      "\u001b[1mCONFIDENCE\u001b[0m One must have the adventurous daring to accept oneself as a bundle of possibilities and undertake the most interesting game in the world - making the most of one's best.\n",
      "\u001b[1mCONFIDENCE\u001b[0m Be proud to wear you.\n",
      "\u001b[1mCONFIDENCE\u001b[0m I was always looking outside myself for strength and confidence but it comes from within. It is there all the time.\n",
      "\u001b[1mCONFIDENCE\u001b[0m Every small positive change we make in ourselves repays us in confidence in the future.\n",
      "\u001b[1mLOVE\u001b[0m Love does not dominate; it cultivates.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "   \n",
    "URL = \"http://www.values.com/inspirational-quotes\"\n",
    "r = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(r.content, 'html5lib')   \n",
    "table = soup.find('div', attrs = {'id':'all_quotes'}) \n",
    "   \n",
    "for row in table.findAll('div', attrs = {'class':'col-6 col-lg-4 text-center margin-30px-bottom sm-margin-30px-top'}):\n",
    "    print('\\033[1m' + row.h5.text +'\\033[0m', row.img['alt'].split(\" #\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using RPA tools like UiPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RPA tools also require similar kind of knowing the website as you do for manual scraping. The difference is that RPA tools don't require coding. Most RPA tools have a very good graphic user interface and are very user-friendly. They even assist users to know the structure of website by simple drag and drop of elements of interest.\n",
    "\n",
    "Here is example of simple scrapping using UiPath RPA tool:\n",
    "\n",
    "https://www.youtube.com/watch?v=jDKo4sax0SY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
